## Lab2_DL 算法部分报告

2019.5.29 by 张永停 PB17111585

### 算法原理

----

<!--算法是什么？基本原理？优势与不足？-->

#### 训练模型

- 算法以及具体实现

  - 由于此次实验~~是在数理方程考试后才开始做~~数据集个人团体收集较小，因此考虑迁移学习。
  - 本次实验采用Inception-v3模型，通过Inception-v3提取特征向量（瓶颈层），然后添加一层全连接层。通过训练确定全连接层的参数。

  - <img src="imgs/ince.jpg">

  ​	*Inception-v3模型，红色箭头前面部分是卷积层，后面是全连接层*

  - Inception-v3最后一个卷积层激活函数的输出值个数为2048，我们图片共有31个分类。全连接层的输入就是Inception-v3最后一个卷积层激活函数的输出值（2048维向量）。
  - 定义交叉熵作为损失函数，使用反向传播训练。训练时仅训练全连接层的参数。
  - 为了加快训练速度，我们将图片 的特征值缓存到硬盘中，这样在图片第二次被抽中训练时，可以直接从硬盘中读取特征值作为全连接层的输入数据。
  - 但如果使用该模块下的数据增广，则不会缓存特征值
  - 训练集，测试集，验证集默认比例8：1：1
  - 通过TensorBorad可视化

- 基本原理

  - Inception-v3由谷歌提出，主要用于ImageNet的大规模视觉识别任务。本次实验目的是对动漫人物进行分类，与Inception-v3任务相似。因此可以借用该模型当作特征提取器，只训练最后的全连接层。

- 优势与不足

  - Inception-v3反复使用了Inception Block，涉及大量的卷积和池化。其错误率只有3.5%。使用该模型当特征提取器准确率较高，且迁移学习不需要太大的数据集即可得到较准确的结果。
  - 直接使用Inception-v3来提取特征可能会导致训练效果有点差，不过总体来说这是我们在手头数据集不够大的情况下最好的选择。

#### 数据增广

- 最初数据集大小7000多，直接进行训练，效果其实并不是太理想(~~其实也还可以~~)。

- *此处结果图片*

- 后来采用retrain.py中的数据增广操作（剪切，放缩，翻转，改变透明度），这样便不能提前缓存图片的特征向量，因为在每次抽中图片时对图片所做操作可能不一样，于是导致了速度极慢，~~我跑了一天+一晚上才跑出结果~~。但虽然跑了这么久，结果却并不是很理想，最终训练结果甚至没有没有数据增广时效果好TAT。

- *此处结果图片*

- 后来经过~~沉重的反思~~，我们发现是因为上述数据增广其实对动漫人物识别作用并不是很大。于是乎，便开始认真上网查找数据增广的方法，最终，我决定使用imgaug库来做数据增广(~~此处吐血三升，要是早点查就好了~~)。

- 由于许多动漫人物的重要区别点是头发和眼睛的颜色，因此我在进行数据增广时并没有选择改变像素的操作。本次数据增广主要有:镜像翻转，剪切，放缩，旋转，仿射变换(矩形变为平行四边形)，全白或全黑填充，高斯模糊，均值模糊，中值模糊，锐化处理，浮雕效果，改变对比度，移动像素，扭曲图像局部区域。这些操作会随机的被应用到图片上。考虑到数据集的大小，我选择将一张图片增广64张。

- <figure class="half">
      <img src="imgs/aug2.jpg" width="295">
      <img src="imgs/aug1.jpg" width="465">
  </figure>

  *数据增广的效果*

- *此处结果**此处附数据集地址,同时修改一下提出来后缀名使应用更广**

#### 输入图像分类

- 此部分就没什么技术含量(雾)。
- 将输入图片传入训练好的模型(**此处附训练好的模型的地址**)，根据模型的输出值(31维向量)来判断该图片是哪一个动漫人物，并输出概率前五。

### 实验细节

------

<!--调整参数？修改loss函数?修改训练过程？以及一些其它有用或者没用的修改？最终训练的epoch,指标-->







### 实验总结

------

<!--实验结果的分析，心得与体会-->





### 参考资料

-----



